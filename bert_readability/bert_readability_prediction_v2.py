# -*- coding: utf-8 -*-
"""BERT Readability Prediction v2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FjnXCO3j-KITg1DM4o5kcZamXL5XGEC_

Setup
"""

import os
os.environ['KAGGLE_CONFIG_DIR'] = "./"
!kaggle datasets download -d shreymalvi/attention-data
!unzip "attention-data.zip"  && rm "attention-data.zip"

!pip install transformers

import numpy as np
import pandas as pd
import random
import tensorflow as tf
from tensorflow.keras import backend as K
from transformers import RobertaTokenizer, TFRobertaModel
from transformers import RobertaConfig, RobertaModel
from tensorflow.keras.layers import Layer

MAX_LEN = 250
MODEL = 'roberta-base'
tokenizer = RobertaTokenizer.from_pretrained(MODEL)

def regular_encode(texts, tokenizer, maxlen = MAX_LEN):
    enc_di = tokenizer.batch_encode_plus(
        texts,
        padding = 'max_length',
        truncation = True,
        max_length = maxlen,
    )
    return np.array(enc_di['input_ids'])
def encode_texts(x_test, MAX_LEN):
    x_test = regular_encode(x_test.tolist(), tokenizer, maxlen = MAX_LEN)
    return x_test
class attention(Layer):
    def __init__(self,**kwargs):
        super(attention,self).__init__(**kwargs)

    def build(self,input_shape):
        self.W=self.add_weight(name="att_weight",shape=(input_shape[-1],1),initializer="normal")
        self.b=self.add_weight(name="att_bias",shape=(input_shape[1],1),initializer="zeros")        
        super(attention, self).build(input_shape)

    def call(self,x):
        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)
        at=K.softmax(et)
        at=K.expand_dims(at,axis=-1)
        output=x*at
        return K.sum(output,axis=1)

    def compute_output_shape(self,input_shape):
        return (input_shape[0],input_shape[-1])

    def get_config(self):
        return super(attention,self).get_config()

def build_roberta_attention_model(max_len = MAX_LEN):
    transformer = TFRobertaModel.from_pretrained(MODEL)
    input_word_ids = tf.keras.layers.Input(shape = (max_len, ), dtype = tf.int32, name = 'input_word_ids')
    sequence_output = transformer(input_word_ids)[0]
    sequence = sequence_output[:, 1:, :]
    att_out=attention()(sequence)
    dense1 = tf.keras.layers.Dense(128, activation="relu")(att_out)
    output = tf.keras.layers.Dense(1, activation = 'linear', dtype = 'float32')(dense1)
    model = tf.keras.models.Model(inputs = [input_word_ids], outputs = [output])
    return model

model = build_roberta_attention_model(max_len = MAX_LEN)
model.load_weights('Roberta_Base_attention1_123.h5')

"""# BERT Features

Excerpts
"""

excerpts_df = pd.read_csv('bert_excerpts.csv')
excerpts = encode_texts(excerpts_df['excerpt'], MAX_LEN)
excerpts_df

### for finding 768 BERT features
interm_model = tf.keras.models.Model(inputs=model.input,outputs=model.get_layer(index=3).output)
embedding_preds = interm_model.predict(excerpts, batch_size = 16, verbose = 1).reshape((-1,768))
excerpts_bert_feature_df = pd.DataFrame(data=embedding_preds, index=excerpts_df.index, columns = ['feature_' + str(i + 1) for i in range(embedding_preds.shape[1])])
excerpts_bert_feature_df.insert(0, 'enum', excerpts_df['enum'])
excerpts_bert_feature_df.to_csv('colab_export_excerpts_bertfeats.csv',index=None)
excerpts_bert_feature_df

"""Machine Translations"""

translations_df = pd.read_csv('bert_translations.csv')
translations = encode_texts(translations_df['translation'], MAX_LEN)
translations_df

### for finding 768 BERT features
interm_model = tf.keras.models.Model(inputs=model.input,outputs=model.get_layer(index=3).output)
embedding_preds = interm_model.predict(translations, batch_size = 16, verbose = 1).reshape((-1,768))
translations_bert_feature_df = pd.DataFrame(data=embedding_preds, index=translations_df.index, columns = ['feature_' + str(i + 1) for i in range(embedding_preds.shape[1])])
translations_bert_feature_df.insert(0, 'enum', translations_df['enum'])
translations_bert_feature_df.insert(1, 'condcode', translations_df['condcode'])
translations_bert_feature_df.insert(2, 'tnum', translations_df['tnum'])
translations_bert_feature_df.to_csv('colab_export_translations_bertfeats.csv',index=None)
translations_bert_feature_df

"""Excerpts for fewshot training and their human translations"""

prompt_excerpts_rephrased_df = pd.read_csv('gsheet_export_prompt_excerpts_rephrased.csv')
prompt_excerpts = encode_texts(prompt_excerpts_rephrased_df['excerpt'], MAX_LEN)
prompt_rephrases = encode_texts(prompt_excerpts_rephrased_df['rephrased'], MAX_LEN)

# 768 bert features

interm_model = tf.keras.models.Model(inputs=model.input,outputs=model.get_layer(index=3).output)

embedding_preds_prompt_excerpts = interm_model.predict(prompt_excerpts, batch_size = 16, verbose = 1).reshape((-1,768))
embedding_preds_prompt_rephrases = interm_model.predict(prompt_rephrases, batch_size = 16, verbose = 1).reshape((-1,768))

# excerpts
excerpts_bertfeat_df = pd.DataFrame(data=embedding_preds_prompt_excerpts, index=prompt_excerpts_rephrased_df.index, columns = ['feature_' + str(i + 1) for i in range(embedding_preds_prompt_excerpts.shape[1])])
excerpts_bertfeat_df.insert(0, 'enum', prompt_excerpts_rephrased_df['enum'])
excerpts_bertfeat_df.insert(1, 'tnum', prompt_excerpts_rephrased_df['tnum'])
excerpts_bertfeat_df.to_csv('colab_export_prompt_excerpt_bertfeats.csv',index=None)

# human rephrases
rephrases_bertfeat_df = pd.DataFrame(data=embedding_preds_prompt_rephrases, index=prompt_excerpts_rephrased_df.index, columns = ['feature_' + str(i + 1) for i in range(embedding_preds_prompt_rephrases.shape[1])])
rephrases_bertfeat_df.insert(0, 'enum', prompt_excerpts_rephrased_df['enum'])
rephrases_bertfeat_df.insert(1, 'tnum', prompt_excerpts_rephrased_df['tnum'])
rephrases_bertfeat_df.to_csv('colab_export_prompt_rephrased_bertfeats.csv',index=None)

# data preview
rephrases_bertfeat_df

"""# Readability metrics

Excerpts
"""

preds = model.predict(excerpts, batch_size = 16, verbose = 1)
excerpts_readability_df = excerpts_df.copy()
excerpts_readability_df['bert'] = preds
excerpts_readability_df.to_csv('colab_export_excerpts_bert_readability.csv',index=None)
excerpts_readability_df

"""Translation"""

preds = model.predict(translations, batch_size = 16, verbose = 1)
translations_readability_df = translations_df.copy()
translations_readability_df['bert_trn'] = preds
translations_readability_df.to_csv('colab_export_translations_bert_readability.csv',index=None)
translations_readability_df

"""Prompt excerpts and human rephrases in one file"""

prompt_excerpts_preds = model.predict(prompt_excerpts, batch_size = 16, verbose = 1)
prompt_rephrases_preds = model.predict(prompt_rephrases, batch_size = 16, verbose = 1)

prompt_excerpts_rephrased_readability_df = prompt_excerpts_rephrased_df.copy()

prompt_excerpts_rephrased_readability_df['bert'] = prompt_excerpts_preds
prompt_excerpts_rephrased_readability_df['bert_trn'] = prompt_rephrases_preds

prompt_excerpts_rephrased_readability_df.to_csv('colab_export_prompt_excerpts_rephrased_readability.csv',index=None)
prompt_excerpts_rephrased_readability_df